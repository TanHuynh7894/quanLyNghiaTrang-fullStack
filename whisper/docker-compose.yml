services:
  whisper-asr:
    build:
      context: ./server
    image: whisper-gpu-server
    container_name: whisper-asr
    ports:
      - "8010:8000"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: ["gpu"]
    environment:
      CT2_DEVICE: "cuda"
      CT2_COMPUTE_TYPE: "float16"
      WHISPER__INFERENCE_DEVICE: "cuda"
      WHISPER__COMPUTE_TYPE: "float16"
      DEFAULT_MODEL: "Systran/faster-whisper-large-v3"
      HF_HOME: "/root/.cache/huggingface"
    volumes:
      - "E:/D/vnpt/quanLyNghiaTrang_1/whisper/.cache/huggingface:/root/.cache/huggingface"
    restart: unless-stopped
    command: ["uvicorn","app:app","--host","0.0.0.0","--port","8000","--timeout-keep-alive","120","--log-level","info"]
